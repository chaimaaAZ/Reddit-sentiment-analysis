{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from praw import Reddit\n",
    "from praw.models import Subreddit, Submission\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, date, timedelta\n",
    "from dotenv import dotenv_values\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from datetime import datetime\n",
    "from dotenv import dotenv_values\n",
    "import pandas as pd\n",
    "\n",
    "# Load environment variables\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "# Initialize Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=config[\"CLIENT_ID\"],\n",
    "    client_secret=config[\"CLIENT_SECRET\"],\n",
    "    redirect_uri=config[\"REDIRECT_URL\"],\n",
    "    user_agent=config[\"USER_AGENT\"]\n",
    ")\n",
    "\n",
    "def fetch_posts_about_keyword(subreddit_name, keywords, limit=500000):\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    data = []\n",
    "    \n",
    "    # Define the cutoff date (before November 2024)\n",
    "    cutoff_date = datetime(2024, 11, 30)  # November 1, 2024\n",
    "    \n",
    "    # Fetch posts from subreddit\n",
    "    for post in subreddit.search(' '.join(keywords), time_filter='all', limit=limit):\n",
    "        post_date = datetime.utcfromtimestamp(post.created)\n",
    "        \n",
    "        # Check if the post is before the cutoff date\n",
    "        if post_date < cutoff_date:\n",
    "            matching_keywords = [keyword for keyword in keywords if keyword.lower() in post.title.lower()]\n",
    "\n",
    "            for keyword in matching_keywords:\n",
    "                post.comments.replace_more(limit=0)\n",
    "                comments = post.comments.list()\n",
    "\n",
    "                for comment in comments:\n",
    "                    data.append({\n",
    "                        'post_title': post.title,\n",
    "                        'post_score': post.score,\n",
    "                        'post_id': post.id,\n",
    "                        'post_num_comments': post.num_comments,\n",
    "                        'post_created': post_date,\n",
    "                        'post_body': post.selftext,\n",
    "                        'comment_id': comment.id,\n",
    "                        'comment_body': comment.body,\n",
    "                        'comment_score': comment.score,\n",
    "                        'matched_keywords': \", \".join(matching_keywords)\n",
    "                    })\n",
    "                break  # Only process the post once per matching keyword\n",
    "\n",
    "    return data\n",
    "\n",
    "subreddit_name = \"stocks\"\n",
    "keywords = [\"Uber\", \"youtube\", \"meta\", \"apple\", \"nvidia\", \"microsoft\", \"amazon\", \"Saudi Arabian Oil Co\", \"intel\", \"tesla\", \"MARA Holdings\"]\n",
    "\n",
    "# Fetch posts before November 2024\n",
    "data = fetch_posts_about_keyword(subreddit_name, keywords, limit=1000)\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"posts_before_november_2024.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_score</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_num_comments</th>\n",
       "      <th>post_created</th>\n",
       "      <th>post_body</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>matched_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nvidia passes Microsoft in market cap to becom...</td>\n",
       "      <td>2035</td>\n",
       "      <td>1divtu5</td>\n",
       "      <td>512</td>\n",
       "      <td>2024-06-18 17:07:58</td>\n",
       "      <td>Nvidia, long known in the niche gaming communi...</td>\n",
       "      <td>l96k3bm</td>\n",
       "      <td>The first trillion is always the hardest. Now ...</td>\n",
       "      <td>980</td>\n",
       "      <td>nvidia, microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nvidia passes Microsoft in market cap to becom...</td>\n",
       "      <td>2035</td>\n",
       "      <td>1divtu5</td>\n",
       "      <td>512</td>\n",
       "      <td>2024-06-18 17:07:58</td>\n",
       "      <td>Nvidia, long known in the niche gaming communi...</td>\n",
       "      <td>l96lcmg</td>\n",
       "      <td>I keep waiting to see NVDA slide back a bit or...</td>\n",
       "      <td>523</td>\n",
       "      <td>nvidia, microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nvidia passes Microsoft in market cap to becom...</td>\n",
       "      <td>2035</td>\n",
       "      <td>1divtu5</td>\n",
       "      <td>512</td>\n",
       "      <td>2024-06-18 17:07:58</td>\n",
       "      <td>Nvidia, long known in the niche gaming communi...</td>\n",
       "      <td>l96ukx9</td>\n",
       "      <td>Really should have invested in Nvidia when I d...</td>\n",
       "      <td>244</td>\n",
       "      <td>nvidia, microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nvidia passes Microsoft in market cap to becom...</td>\n",
       "      <td>2035</td>\n",
       "      <td>1divtu5</td>\n",
       "      <td>512</td>\n",
       "      <td>2024-06-18 17:07:58</td>\n",
       "      <td>Nvidia, long known in the niche gaming communi...</td>\n",
       "      <td>l96oygx</td>\n",
       "      <td>&gt; “When I see a bubble forming, I rush in to b...</td>\n",
       "      <td>147</td>\n",
       "      <td>nvidia, microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nvidia passes Microsoft in market cap to becom...</td>\n",
       "      <td>2035</td>\n",
       "      <td>1divtu5</td>\n",
       "      <td>512</td>\n",
       "      <td>2024-06-18 17:07:58</td>\n",
       "      <td>Nvidia, long known in the niche gaming communi...</td>\n",
       "      <td>l97ui72</td>\n",
       "      <td>I was deciding to buy between AMD and NVDA a c...</td>\n",
       "      <td>55</td>\n",
       "      <td>nvidia, microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>Stocks are advancing ahead of earnings results...</td>\n",
       "      <td>24</td>\n",
       "      <td>9r9niy</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-25 12:03:39</td>\n",
       "      <td>\\n\\n### US Stocks\\n\\n* **Global stocks are ad...</td>\n",
       "      <td>e8fiiir</td>\n",
       "      <td>Seriously. I’ve been buying all of the last tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon, intel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>Stocks are advancing ahead of earnings results...</td>\n",
       "      <td>24</td>\n",
       "      <td>9r9niy</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-25 12:03:39</td>\n",
       "      <td>\\n\\n### US Stocks\\n\\n* **Global stocks are ad...</td>\n",
       "      <td>e8fk3jn</td>\n",
       "      <td>The children aren't used to pullbacks.They sca...</td>\n",
       "      <td>3</td>\n",
       "      <td>amazon, intel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>Stocks are advancing ahead of earnings results...</td>\n",
       "      <td>24</td>\n",
       "      <td>9r9niy</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-25 12:03:39</td>\n",
       "      <td>\\n\\n### US Stocks\\n\\n* **Global stocks are ad...</td>\n",
       "      <td>e8frw0t</td>\n",
       "      <td>Depends what kind of stocks we are talking abo...</td>\n",
       "      <td>3</td>\n",
       "      <td>amazon, intel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>Stocks are advancing ahead of earnings results...</td>\n",
       "      <td>24</td>\n",
       "      <td>9r9niy</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-25 12:03:39</td>\n",
       "      <td>\\n\\n### US Stocks\\n\\n* **Global stocks are ad...</td>\n",
       "      <td>e8fs10p</td>\n",
       "      <td>I waited for solid companies like ADBE, AMZN, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>amazon, intel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>Stocks are advancing ahead of earnings results...</td>\n",
       "      <td>24</td>\n",
       "      <td>9r9niy</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-25 12:03:39</td>\n",
       "      <td>\\n\\n### US Stocks\\n\\n* **Global stocks are ad...</td>\n",
       "      <td>e8g3wc7</td>\n",
       "      <td>Idk how much cash you have, but unless you are...</td>\n",
       "      <td>2</td>\n",
       "      <td>amazon, intel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2238 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             post_title  post_score  post_id   \n",
       "0     Nvidia passes Microsoft in market cap to becom...        2035  1divtu5  \\\n",
       "1     Nvidia passes Microsoft in market cap to becom...        2035  1divtu5   \n",
       "2     Nvidia passes Microsoft in market cap to becom...        2035  1divtu5   \n",
       "3     Nvidia passes Microsoft in market cap to becom...        2035  1divtu5   \n",
       "4     Nvidia passes Microsoft in market cap to becom...        2035  1divtu5   \n",
       "...                                                 ...         ...      ...   \n",
       "2233  Stocks are advancing ahead of earnings results...          24   9r9niy   \n",
       "2234  Stocks are advancing ahead of earnings results...          24   9r9niy   \n",
       "2235  Stocks are advancing ahead of earnings results...          24   9r9niy   \n",
       "2236  Stocks are advancing ahead of earnings results...          24   9r9niy   \n",
       "2237  Stocks are advancing ahead of earnings results...          24   9r9niy   \n",
       "\n",
       "      post_num_comments        post_created   \n",
       "0                   512 2024-06-18 17:07:58  \\\n",
       "1                   512 2024-06-18 17:07:58   \n",
       "2                   512 2024-06-18 17:07:58   \n",
       "3                   512 2024-06-18 17:07:58   \n",
       "4                   512 2024-06-18 17:07:58   \n",
       "...                 ...                 ...   \n",
       "2233                  9 2018-10-25 12:03:39   \n",
       "2234                  9 2018-10-25 12:03:39   \n",
       "2235                  9 2018-10-25 12:03:39   \n",
       "2236                  9 2018-10-25 12:03:39   \n",
       "2237                  9 2018-10-25 12:03:39   \n",
       "\n",
       "                                              post_body comment_id   \n",
       "0     Nvidia, long known in the niche gaming communi...    l96k3bm  \\\n",
       "1     Nvidia, long known in the niche gaming communi...    l96lcmg   \n",
       "2     Nvidia, long known in the niche gaming communi...    l96ukx9   \n",
       "3     Nvidia, long known in the niche gaming communi...    l96oygx   \n",
       "4     Nvidia, long known in the niche gaming communi...    l97ui72   \n",
       "...                                                 ...        ...   \n",
       "2233   \\n\\n### US Stocks\\n\\n* **Global stocks are ad...    e8fiiir   \n",
       "2234   \\n\\n### US Stocks\\n\\n* **Global stocks are ad...    e8fk3jn   \n",
       "2235   \\n\\n### US Stocks\\n\\n* **Global stocks are ad...    e8frw0t   \n",
       "2236   \\n\\n### US Stocks\\n\\n* **Global stocks are ad...    e8fs10p   \n",
       "2237   \\n\\n### US Stocks\\n\\n* **Global stocks are ad...    e8g3wc7   \n",
       "\n",
       "                                           comment_body  comment_score   \n",
       "0     The first trillion is always the hardest. Now ...            980  \\\n",
       "1     I keep waiting to see NVDA slide back a bit or...            523   \n",
       "2     Really should have invested in Nvidia when I d...            244   \n",
       "3     > “When I see a bubble forming, I rush in to b...            147   \n",
       "4     I was deciding to buy between AMD and NVDA a c...             55   \n",
       "...                                                 ...            ...   \n",
       "2233  Seriously. I’ve been buying all of the last tw...              0   \n",
       "2234  The children aren't used to pullbacks.They sca...              3   \n",
       "2235  Depends what kind of stocks we are talking abo...              3   \n",
       "2236  I waited for solid companies like ADBE, AMZN, ...              3   \n",
       "2237  Idk how much cash you have, but unless you are...              2   \n",
       "\n",
       "       matched_keywords  \n",
       "0     nvidia, microsoft  \n",
       "1     nvidia, microsoft  \n",
       "2     nvidia, microsoft  \n",
       "3     nvidia, microsoft  \n",
       "4     nvidia, microsoft  \n",
       "...                 ...  \n",
       "2233      amazon, intel  \n",
       "2234      amazon, intel  \n",
       "2235      amazon, intel  \n",
       "2236      amazon, intel  \n",
       "2237      amazon, intel  \n",
       "\n",
       "[2238 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching posts for keyword: Uber\n",
      "Fetching posts for keyword: youtube\n",
      "Fetching posts for keyword: meta\n",
      "Fetching posts for keyword: apple\n",
      "Fetching posts for keyword: nvidia\n",
      "Fetching posts for keyword: microsoft\n",
      "Fetching posts for keyword: amazon\n",
      "Fetching posts for keyword: Saudi Arabian Oil Co\n",
      "Fetching posts for keyword: intel\n",
      "Fetching posts for keyword: tesla\n",
      "Fetching posts for keyword: MARA Holdings\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "# Initialize Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=config[\"CLIENT_ID\"],\n",
    "    client_secret=config[\"CLIENT_SECRET\"],\n",
    "    user_agent=config[\"USER_AGENT\"]\n",
    ")\n",
    "\n",
    "def fetch_posts_about_keywords(subreddit_name, keywords, limit=500000):\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    data = []\n",
    "    \n",
    "    # Define the date range for March and April (2024)\n",
    "    today = datetime(2024, 9, 30, 23, 59, 59)  # End of April\n",
    "    start_date = datetime(2024, 7, 1)  # Start of March\n",
    "    \n",
    "    # Iterate through each keyword\n",
    "    for keyword in keywords:\n",
    "        print(f\"Fetching posts for keyword: {keyword}\")\n",
    "        for post in subreddit.search(keyword, time_filter='all', limit=limit):\n",
    "            post_date = datetime.utcfromtimestamp(post.created)\n",
    "            \n",
    "            # Check if the post is within the desired time range\n",
    "            if start_date <= post_date <= today:\n",
    "                post.comments.replace_more(limit=0)\n",
    "                comments = post.comments.list()\n",
    "\n",
    "                for comment in comments:\n",
    "                    data.append({\n",
    "                        'post_title': post.title,\n",
    "                        'post_score': post.score,\n",
    "                        'post_id': post.id,\n",
    "                        'post_num_comments': post.num_comments,\n",
    "                        'post_created': post_date,\n",
    "                        'post_body': post.selftext,\n",
    "                        'comment_id': comment.id,\n",
    "                        'comment_body': comment.body,\n",
    "                        'comment_score': comment.score,\n",
    "                        'matched_keyword': keyword\n",
    "                    })\n",
    "    \n",
    "    return data\n",
    "\n",
    "subreddit_name = \"stocks\"\n",
    "keywords = [\"Uber\", \"youtube\", \"meta\", \"apple\", \"nvidia\", \"microsoft\", \"amazon\", \"Saudi Arabian Oil Co\", \"intel\", \"tesla\", \"MARA Holdings\"]\n",
    "\n",
    "# Fetch posts from March and April 2024\n",
    "data = fetch_posts_about_keywords(subreddit_name, keywords, limit=500000)\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"before_september_reddit_comments.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_score</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_num_comments</th>\n",
       "      <th>post_created</th>\n",
       "      <th>post_body</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>matched_keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uber and Waymo to offer driverless ride-sharin...</td>\n",
       "      <td>218</td>\n",
       "      <td>1ffw4rb</td>\n",
       "      <td>83</td>\n",
       "      <td>2024-09-13 14:29:17</td>\n",
       "      <td>Uber announced Friday it is expanding its part...</td>\n",
       "      <td>lmxzxby</td>\n",
       "      <td>This is really interesting to me because isn't...</td>\n",
       "      <td>30</td>\n",
       "      <td>Uber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uber and Waymo to offer driverless ride-sharin...</td>\n",
       "      <td>218</td>\n",
       "      <td>1ffw4rb</td>\n",
       "      <td>83</td>\n",
       "      <td>2024-09-13 14:29:17</td>\n",
       "      <td>Uber announced Friday it is expanding its part...</td>\n",
       "      <td>lmyho7c</td>\n",
       "      <td>Clearly Waymo wants to license its technology ...</td>\n",
       "      <td>37</td>\n",
       "      <td>Uber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uber and Waymo to offer driverless ride-sharin...</td>\n",
       "      <td>218</td>\n",
       "      <td>1ffw4rb</td>\n",
       "      <td>83</td>\n",
       "      <td>2024-09-13 14:29:17</td>\n",
       "      <td>Uber announced Friday it is expanding its part...</td>\n",
       "      <td>lmz6qiq</td>\n",
       "      <td>Despite the narrative that driverless tech is ...</td>\n",
       "      <td>9</td>\n",
       "      <td>Uber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uber and Waymo to offer driverless ride-sharin...</td>\n",
       "      <td>218</td>\n",
       "      <td>1ffw4rb</td>\n",
       "      <td>83</td>\n",
       "      <td>2024-09-13 14:29:17</td>\n",
       "      <td>Uber announced Friday it is expanding its part...</td>\n",
       "      <td>lmxw2fk</td>\n",
       "      <td>Sort of related - month ago I mentioned (https...</td>\n",
       "      <td>16</td>\n",
       "      <td>Uber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uber and Waymo to offer driverless ride-sharin...</td>\n",
       "      <td>218</td>\n",
       "      <td>1ffw4rb</td>\n",
       "      <td>83</td>\n",
       "      <td>2024-09-13 14:29:17</td>\n",
       "      <td>Uber announced Friday it is expanding its part...</td>\n",
       "      <td>lmzo0cc</td>\n",
       "      <td>If successful, I hope either company decides t...</td>\n",
       "      <td>4</td>\n",
       "      <td>Uber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33449</th>\n",
       "      <td>These are the stocks on my watchlist (8/1)</td>\n",
       "      <td>35</td>\n",
       "      <td>1ehgi7k</td>\n",
       "      <td>17</td>\n",
       "      <td>2024-08-01 13:20:18</td>\n",
       "      <td>Hi! I am an ex-prop shop equity trader. This i...</td>\n",
       "      <td>lfzblj8</td>\n",
       "      <td>I have more shares of NVDL because I sell cove...</td>\n",
       "      <td>4</td>\n",
       "      <td>MARA Holdings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33450</th>\n",
       "      <td>These are the stocks on my watchlist (8/1)</td>\n",
       "      <td>35</td>\n",
       "      <td>1ehgi7k</td>\n",
       "      <td>17</td>\n",
       "      <td>2024-08-01 13:20:18</td>\n",
       "      <td>Hi! I am an ex-prop shop equity trader. This i...</td>\n",
       "      <td>lg01jpi</td>\n",
       "      <td>It's doing well, but as expected I have a few ...</td>\n",
       "      <td>2</td>\n",
       "      <td>MARA Holdings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33451</th>\n",
       "      <td>These are the stocks on my watchlist (8/1)</td>\n",
       "      <td>35</td>\n",
       "      <td>1ehgi7k</td>\n",
       "      <td>17</td>\n",
       "      <td>2024-08-01 13:20:18</td>\n",
       "      <td>Hi! I am an ex-prop shop equity trader. This i...</td>\n",
       "      <td>lfzce7c</td>\n",
       "      <td>Fair enough, if you're cognizant of the risks ...</td>\n",
       "      <td>4</td>\n",
       "      <td>MARA Holdings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33452</th>\n",
       "      <td>These are the stocks on my watchlist (8/1)</td>\n",
       "      <td>35</td>\n",
       "      <td>1ehgi7k</td>\n",
       "      <td>17</td>\n",
       "      <td>2024-08-01 13:20:18</td>\n",
       "      <td>Hi! I am an ex-prop shop equity trader. This i...</td>\n",
       "      <td>lg38j33</td>\n",
       "      <td>&gt;I lost about 20K a few years back for falling...</td>\n",
       "      <td>2</td>\n",
       "      <td>MARA Holdings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33453</th>\n",
       "      <td>These are the stocks on my watchlist (8/1)</td>\n",
       "      <td>35</td>\n",
       "      <td>1ehgi7k</td>\n",
       "      <td>17</td>\n",
       "      <td>2024-08-01 13:20:18</td>\n",
       "      <td>Hi! I am an ex-prop shop equity trader. This i...</td>\n",
       "      <td>lg533ma</td>\n",
       "      <td>Yes. I was new to investing and just got in it...</td>\n",
       "      <td>2</td>\n",
       "      <td>MARA Holdings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33454 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              post_title  post_score  post_id   \n",
       "0      Uber and Waymo to offer driverless ride-sharin...         218  1ffw4rb  \\\n",
       "1      Uber and Waymo to offer driverless ride-sharin...         218  1ffw4rb   \n",
       "2      Uber and Waymo to offer driverless ride-sharin...         218  1ffw4rb   \n",
       "3      Uber and Waymo to offer driverless ride-sharin...         218  1ffw4rb   \n",
       "4      Uber and Waymo to offer driverless ride-sharin...         218  1ffw4rb   \n",
       "...                                                  ...         ...      ...   \n",
       "33449         These are the stocks on my watchlist (8/1)          35  1ehgi7k   \n",
       "33450         These are the stocks on my watchlist (8/1)          35  1ehgi7k   \n",
       "33451         These are the stocks on my watchlist (8/1)          35  1ehgi7k   \n",
       "33452         These are the stocks on my watchlist (8/1)          35  1ehgi7k   \n",
       "33453         These are the stocks on my watchlist (8/1)          35  1ehgi7k   \n",
       "\n",
       "       post_num_comments        post_created   \n",
       "0                     83 2024-09-13 14:29:17  \\\n",
       "1                     83 2024-09-13 14:29:17   \n",
       "2                     83 2024-09-13 14:29:17   \n",
       "3                     83 2024-09-13 14:29:17   \n",
       "4                     83 2024-09-13 14:29:17   \n",
       "...                  ...                 ...   \n",
       "33449                 17 2024-08-01 13:20:18   \n",
       "33450                 17 2024-08-01 13:20:18   \n",
       "33451                 17 2024-08-01 13:20:18   \n",
       "33452                 17 2024-08-01 13:20:18   \n",
       "33453                 17 2024-08-01 13:20:18   \n",
       "\n",
       "                                               post_body comment_id   \n",
       "0      Uber announced Friday it is expanding its part...    lmxzxby  \\\n",
       "1      Uber announced Friday it is expanding its part...    lmyho7c   \n",
       "2      Uber announced Friday it is expanding its part...    lmz6qiq   \n",
       "3      Uber announced Friday it is expanding its part...    lmxw2fk   \n",
       "4      Uber announced Friday it is expanding its part...    lmzo0cc   \n",
       "...                                                  ...        ...   \n",
       "33449  Hi! I am an ex-prop shop equity trader. This i...    lfzblj8   \n",
       "33450  Hi! I am an ex-prop shop equity trader. This i...    lg01jpi   \n",
       "33451  Hi! I am an ex-prop shop equity trader. This i...    lfzce7c   \n",
       "33452  Hi! I am an ex-prop shop equity trader. This i...    lg38j33   \n",
       "33453  Hi! I am an ex-prop shop equity trader. This i...    lg533ma   \n",
       "\n",
       "                                            comment_body  comment_score   \n",
       "0      This is really interesting to me because isn't...             30  \\\n",
       "1      Clearly Waymo wants to license its technology ...             37   \n",
       "2      Despite the narrative that driverless tech is ...              9   \n",
       "3      Sort of related - month ago I mentioned (https...             16   \n",
       "4      If successful, I hope either company decides t...              4   \n",
       "...                                                  ...            ...   \n",
       "33449  I have more shares of NVDL because I sell cove...              4   \n",
       "33450  It's doing well, but as expected I have a few ...              2   \n",
       "33451  Fair enough, if you're cognizant of the risks ...              4   \n",
       "33452  >I lost about 20K a few years back for falling...              2   \n",
       "33453  Yes. I was new to investing and just got in it...              2   \n",
       "\n",
       "      matched_keyword  \n",
       "0                Uber  \n",
       "1                Uber  \n",
       "2                Uber  \n",
       "3                Uber  \n",
       "4                Uber  \n",
       "...               ...  \n",
       "33449   MARA Holdings  \n",
       "33450   MARA Holdings  \n",
       "33451   MARA Holdings  \n",
       "33452   MARA Holdings  \n",
       "33453   MARA Holdings  \n",
       "\n",
       "[33454 rows x 10 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
