{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from praw import Reddit\n",
    "from praw.models import Subreddit, Submission\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, date, timedelta\n",
    "from dotenv import dotenv_values\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from datetime import datetime\n",
    "from dotenv import dotenv_values\n",
    "import pandas as pd\n",
    "\n",
    "# Load environment variables\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "# Initialize Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=config[\"CLIENT_ID\"],\n",
    "    client_secret=config[\"CLIENT_SECRET\"],\n",
    "    redirect_uri=config[\"REDIRECT_URL\"],\n",
    "    user_agent=config[\"USER_AGENT\"]\n",
    ")\n",
    "\n",
    "def fetch_posts_about_keyword(subreddit_name, keywords, limit=500000):\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    data = []\n",
    "    \n",
    "    # Define the cutoff date (before November 2024)\n",
    "    cutoff_date = datetime(2024, 11, 30)  # November 1, 2024\n",
    "    \n",
    "    # Fetch posts from subreddit\n",
    "    for post in subreddit.search(' '.join(keywords), time_filter='all', limit=limit):\n",
    "        post_date = datetime.utcfromtimestamp(post.created)\n",
    "        \n",
    "        # Check if the post is before the cutoff date\n",
    "        if post_date < cutoff_date:\n",
    "            matching_keywords = [keyword for keyword in keywords if keyword.lower() in post.title.lower()]\n",
    "\n",
    "            for keyword in matching_keywords:\n",
    "                post.comments.replace_more(limit=0)\n",
    "                comments = post.comments.list()\n",
    "\n",
    "                for comment in comments:\n",
    "                    data.append({\n",
    "                        'post_title': post.title,\n",
    "                        'post_score': post.score,\n",
    "                        'post_id': post.id,\n",
    "                        'post_num_comments': post.num_comments,\n",
    "                        'post_created': post_date,\n",
    "                        'post_body': post.selftext,\n",
    "                        'comment_id': comment.id,\n",
    "                        'comment_body': comment.body,\n",
    "                        'comment_score': comment.score,\n",
    "                        'matched_keywords': \", \".join(matching_keywords)\n",
    "                    })\n",
    "                break  # Only process the post once per matching keyword\n",
    "\n",
    "    return data\n",
    "\n",
    "subreddit_name = \"stocks\"\n",
    "keywords = [\"Uber\", \"youtube\", \"meta\", \"apple\", \"nvidia\", \"microsoft\", \"amazon\", \"Saudi Arabian Oil Co\", \"intel\", \"tesla\", \"MARA Holdings\"]\n",
    "\n",
    "# Fetch posts before November 2024\n",
    "data = fetch_posts_about_keyword(subreddit_name, keywords, limit=1000)\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"posts_before_november_2024.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_score</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_num_comments</th>\n",
       "      <th>post_created</th>\n",
       "      <th>post_body</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>matched_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nvidia passes Microsoft in market cap to becom...</td>\n",
       "      <td>2035</td>\n",
       "      <td>1divtu5</td>\n",
       "      <td>512</td>\n",
       "      <td>2024-06-18 17:07:58</td>\n",
       "      <td>Nvidia, long known in the niche gaming communi...</td>\n",
       "      <td>l96k3bm</td>\n",
       "      <td>The first trillion is always the hardest. Now ...</td>\n",
       "      <td>980</td>\n",
       "      <td>nvidia, microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nvidia passes Microsoft in market cap to becom...</td>\n",
       "      <td>2035</td>\n",
       "      <td>1divtu5</td>\n",
       "      <td>512</td>\n",
       "      <td>2024-06-18 17:07:58</td>\n",
       "      <td>Nvidia, long known in the niche gaming communi...</td>\n",
       "      <td>l96lcmg</td>\n",
       "      <td>I keep waiting to see NVDA slide back a bit or...</td>\n",
       "      <td>523</td>\n",
       "      <td>nvidia, microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nvidia passes Microsoft in market cap to becom...</td>\n",
       "      <td>2035</td>\n",
       "      <td>1divtu5</td>\n",
       "      <td>512</td>\n",
       "      <td>2024-06-18 17:07:58</td>\n",
       "      <td>Nvidia, long known in the niche gaming communi...</td>\n",
       "      <td>l96ukx9</td>\n",
       "      <td>Really should have invested in Nvidia when I d...</td>\n",
       "      <td>244</td>\n",
       "      <td>nvidia, microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nvidia passes Microsoft in market cap to becom...</td>\n",
       "      <td>2035</td>\n",
       "      <td>1divtu5</td>\n",
       "      <td>512</td>\n",
       "      <td>2024-06-18 17:07:58</td>\n",
       "      <td>Nvidia, long known in the niche gaming communi...</td>\n",
       "      <td>l96oygx</td>\n",
       "      <td>&gt; “When I see a bubble forming, I rush in to b...</td>\n",
       "      <td>147</td>\n",
       "      <td>nvidia, microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nvidia passes Microsoft in market cap to becom...</td>\n",
       "      <td>2035</td>\n",
       "      <td>1divtu5</td>\n",
       "      <td>512</td>\n",
       "      <td>2024-06-18 17:07:58</td>\n",
       "      <td>Nvidia, long known in the niche gaming communi...</td>\n",
       "      <td>l97ui72</td>\n",
       "      <td>I was deciding to buy between AMD and NVDA a c...</td>\n",
       "      <td>55</td>\n",
       "      <td>nvidia, microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>Stocks are advancing ahead of earnings results...</td>\n",
       "      <td>24</td>\n",
       "      <td>9r9niy</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-25 12:03:39</td>\n",
       "      <td>\\n\\n### US Stocks\\n\\n* **Global stocks are ad...</td>\n",
       "      <td>e8fiiir</td>\n",
       "      <td>Seriously. I’ve been buying all of the last tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon, intel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>Stocks are advancing ahead of earnings results...</td>\n",
       "      <td>24</td>\n",
       "      <td>9r9niy</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-25 12:03:39</td>\n",
       "      <td>\\n\\n### US Stocks\\n\\n* **Global stocks are ad...</td>\n",
       "      <td>e8fk3jn</td>\n",
       "      <td>The children aren't used to pullbacks.They sca...</td>\n",
       "      <td>3</td>\n",
       "      <td>amazon, intel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>Stocks are advancing ahead of earnings results...</td>\n",
       "      <td>24</td>\n",
       "      <td>9r9niy</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-25 12:03:39</td>\n",
       "      <td>\\n\\n### US Stocks\\n\\n* **Global stocks are ad...</td>\n",
       "      <td>e8frw0t</td>\n",
       "      <td>Depends what kind of stocks we are talking abo...</td>\n",
       "      <td>3</td>\n",
       "      <td>amazon, intel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>Stocks are advancing ahead of earnings results...</td>\n",
       "      <td>24</td>\n",
       "      <td>9r9niy</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-25 12:03:39</td>\n",
       "      <td>\\n\\n### US Stocks\\n\\n* **Global stocks are ad...</td>\n",
       "      <td>e8fs10p</td>\n",
       "      <td>I waited for solid companies like ADBE, AMZN, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>amazon, intel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>Stocks are advancing ahead of earnings results...</td>\n",
       "      <td>24</td>\n",
       "      <td>9r9niy</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-25 12:03:39</td>\n",
       "      <td>\\n\\n### US Stocks\\n\\n* **Global stocks are ad...</td>\n",
       "      <td>e8g3wc7</td>\n",
       "      <td>Idk how much cash you have, but unless you are...</td>\n",
       "      <td>2</td>\n",
       "      <td>amazon, intel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2238 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             post_title  post_score  post_id   \n",
       "0     Nvidia passes Microsoft in market cap to becom...        2035  1divtu5  \\\n",
       "1     Nvidia passes Microsoft in market cap to becom...        2035  1divtu5   \n",
       "2     Nvidia passes Microsoft in market cap to becom...        2035  1divtu5   \n",
       "3     Nvidia passes Microsoft in market cap to becom...        2035  1divtu5   \n",
       "4     Nvidia passes Microsoft in market cap to becom...        2035  1divtu5   \n",
       "...                                                 ...         ...      ...   \n",
       "2233  Stocks are advancing ahead of earnings results...          24   9r9niy   \n",
       "2234  Stocks are advancing ahead of earnings results...          24   9r9niy   \n",
       "2235  Stocks are advancing ahead of earnings results...          24   9r9niy   \n",
       "2236  Stocks are advancing ahead of earnings results...          24   9r9niy   \n",
       "2237  Stocks are advancing ahead of earnings results...          24   9r9niy   \n",
       "\n",
       "      post_num_comments        post_created   \n",
       "0                   512 2024-06-18 17:07:58  \\\n",
       "1                   512 2024-06-18 17:07:58   \n",
       "2                   512 2024-06-18 17:07:58   \n",
       "3                   512 2024-06-18 17:07:58   \n",
       "4                   512 2024-06-18 17:07:58   \n",
       "...                 ...                 ...   \n",
       "2233                  9 2018-10-25 12:03:39   \n",
       "2234                  9 2018-10-25 12:03:39   \n",
       "2235                  9 2018-10-25 12:03:39   \n",
       "2236                  9 2018-10-25 12:03:39   \n",
       "2237                  9 2018-10-25 12:03:39   \n",
       "\n",
       "                                              post_body comment_id   \n",
       "0     Nvidia, long known in the niche gaming communi...    l96k3bm  \\\n",
       "1     Nvidia, long known in the niche gaming communi...    l96lcmg   \n",
       "2     Nvidia, long known in the niche gaming communi...    l96ukx9   \n",
       "3     Nvidia, long known in the niche gaming communi...    l96oygx   \n",
       "4     Nvidia, long known in the niche gaming communi...    l97ui72   \n",
       "...                                                 ...        ...   \n",
       "2233   \\n\\n### US Stocks\\n\\n* **Global stocks are ad...    e8fiiir   \n",
       "2234   \\n\\n### US Stocks\\n\\n* **Global stocks are ad...    e8fk3jn   \n",
       "2235   \\n\\n### US Stocks\\n\\n* **Global stocks are ad...    e8frw0t   \n",
       "2236   \\n\\n### US Stocks\\n\\n* **Global stocks are ad...    e8fs10p   \n",
       "2237   \\n\\n### US Stocks\\n\\n* **Global stocks are ad...    e8g3wc7   \n",
       "\n",
       "                                           comment_body  comment_score   \n",
       "0     The first trillion is always the hardest. Now ...            980  \\\n",
       "1     I keep waiting to see NVDA slide back a bit or...            523   \n",
       "2     Really should have invested in Nvidia when I d...            244   \n",
       "3     > “When I see a bubble forming, I rush in to b...            147   \n",
       "4     I was deciding to buy between AMD and NVDA a c...             55   \n",
       "...                                                 ...            ...   \n",
       "2233  Seriously. I’ve been buying all of the last tw...              0   \n",
       "2234  The children aren't used to pullbacks.They sca...              3   \n",
       "2235  Depends what kind of stocks we are talking abo...              3   \n",
       "2236  I waited for solid companies like ADBE, AMZN, ...              3   \n",
       "2237  Idk how much cash you have, but unless you are...              2   \n",
       "\n",
       "       matched_keywords  \n",
       "0     nvidia, microsoft  \n",
       "1     nvidia, microsoft  \n",
       "2     nvidia, microsoft  \n",
       "3     nvidia, microsoft  \n",
       "4     nvidia, microsoft  \n",
       "...                 ...  \n",
       "2233      amazon, intel  \n",
       "2234      amazon, intel  \n",
       "2235      amazon, intel  \n",
       "2236      amazon, intel  \n",
       "2237      amazon, intel  \n",
       "\n",
       "[2238 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from datetime import datetime\n",
    "from dotenv import dotenv_values\n",
    "import pandas as pd\n",
    "\n",
    "# Load environment variables\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "# Initialize Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=config[\"CLIENT_ID\"],\n",
    "    client_secret=config[\"CLIENT_SECRET\"],\n",
    "    redirect_uri=config[\"REDIRECT_URL\"],\n",
    "    user_agent=config[\"USER_AGENT\"]\n",
    ")\n",
    "\n",
    "def fetch_posts_about_keyword(subreddit_name, keywords, limit):\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    data = []\n",
    "    \n",
    "    # Define the cutoff date (before May 2024)\n",
    "    cutoff_date = datetime(2024, 5, 1)  # Posts before May 1, 2024\n",
    "    \n",
    "    # Fetch posts from subreddit\n",
    "    for post in subreddit.search(' '.join(keywords), time_filter='all', limit=limit):\n",
    "        post_date = datetime.utcfromtimestamp(post.created)\n",
    "        \n",
    "        # Check if the post is before the cutoff date\n",
    "        if post_date < cutoff_date:\n",
    "            matching_keywords = [keyword for keyword in keywords if keyword.lower() in post.title.lower()]\n",
    "\n",
    "            for keyword in matching_keywords:\n",
    "                post.comments.replace_more(limit=0)\n",
    "                comments = post.comments.list()\n",
    "\n",
    "                for comment in comments:\n",
    "                    data.append({\n",
    "                        'post_title': post.title,\n",
    "                        'post_score': post.score,\n",
    "                        'post_id': post.id,\n",
    "                        'post_num_comments': post.num_comments,\n",
    "                        'post_created': post_date,\n",
    "                        'post_body': post.selftext,\n",
    "                        'comment_id': comment.id,\n",
    "                        'comment_body': comment.body,\n",
    "                        'comment_score': comment.score,\n",
    "                        'matched_keywords': \", \".join(matching_keywords)\n",
    "                    })\n",
    "                break  # Only process the post once per matching keyword\n",
    "\n",
    "    return data\n",
    "\n",
    "subreddit_name = \"stocks\"\n",
    "keywords = [\"Uber\", \"youtube\", \"meta\", \"apple\", \"nvidia\", \"microsoft\", \"amazon\", \"Saudi Arabian Oil Co\", \"intel\", \"tesla\", \"MARA Holdings\"]\n",
    "\n",
    "# Fetch posts before May 2024\n",
    "data = fetch_posts_about_keyword(subreddit_name, keywords, limit=500000)\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"posts_before_may_2024.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
